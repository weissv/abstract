{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Llama-3.1 Refusal Mechanism Analysis\n",
        "\n",
        "**Mechanistic Interpretability Research on Safety Refusal Behaviors**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/weissv/abstract/blob/main/llama_refusal_analysis.ipynb)\n",
        "[![HuggingFace](https://img.shields.io/badge/ü§ó-HuggingFace-yellow)](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)\n",
        "\n",
        "This notebook implements a comprehensive mechanistic interpretability study using **logit-based metrics** and **complete layer scanning**.\n",
        "\n",
        "## üìã What This Does\n",
        "\n",
        "1. **Baseline Analysis**: Test harmful/harmless prompts with text-based classification\n",
        "2. **Activation Patching**: Identify causal components across ALL 32 layers using logit difference metrics\n",
        "3. **Ransomware Analysis**: Investigate bypass vulnerabilities (\"the hole\")\n",
        "4. **Ablation Studies**: Verify necessary components for refusal behavior\n",
        "5. **Interactive Visualizations**: 6 comprehensive Plotly dashboards + CSV summaries\n",
        "\n",
        "## ‚öôÔ∏è Hardware Requirements\n",
        "- **Google Colab with T4 GPU** (15GB VRAM)\n",
        "- **Model**: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
        "- **Python**: 3.10+\n",
        "\n",
        "## üî¨ Key Features\n",
        "- ‚úÖ **Logit-based metrics** instead of text generation (10-20x faster, more precise)\n",
        "- ‚úÖ **Complete layer scan**: All 32 layers √ó 3 components = 96 experiments per prompt pair\n",
        "- ‚úÖ **Ransomware bypass analysis**: Detects activation pattern vulnerabilities\n",
        "- ‚úÖ **6 interactive visualizations**: Heatmaps, bar charts, scatter plots, cascades, stats, bypass analysis\n",
        "- ‚úÖ **Automated token management**: Uses Colab secrets (no manual input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üöÄ Setup\n",
        "### Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OTJz-Z32wM6"
      },
      "source": [
        "### Step 2: Clone Repository & Check Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/weissv/abstract.git\n",
        "%cd abstract\n",
        "\n",
        "# Verify structure\n",
        "print(\"\\nüìÅ Repository Structure:\")\n",
        "!ls -la src/\n",
        "print(\"\\nüìä Experiments:\")\n",
        "!ls -la experiments/\n",
        "print(\"\\n‚úì Repository cloned successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRPZ6dp02wM7"
      },
      "source": [
        "### Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install \"numpy>=1.26.4,<2.0\" --force-reinstall --no-cache-dir\n",
        "os.kill(os.getpid(), 9) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt\n",
        "!pip install --upgrade -q pandas plotly kaleido\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import plotly\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úì Package Versions:\")\n",
        "print(\"=\" * 60)\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'Transformers: {transformers.__version__}')\n",
        "print(f'Plotly: {plotly.__version__}')\n",
        "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'CUDA Device: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlAzex7m2wM7"
      },
      "source": [
        "### Step 4: Setting HuggingFace Token\n",
        "\n",
        "**Important**: Set your HuggingFace token in Colab secrets:\n",
        "1. Click üîë (Key icon) in left sidebar\n",
        "2. Add secret: Name = `HF_TOKEN`, Value = your token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "3. Enable notebook access for the secret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf_login"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9FFFwVf2wM7"
      },
      "source": [
        "## üìä Run Experiments\n",
        "\n",
        "### Experiment 1: Baseline Analysis\n",
        "\n",
        "Tests harmful vs harmless prompts with text-based classification.\n",
        "\n",
        "**Expected outputs**:\n",
        "- `outputs/results/01_baseline_results.json` - Raw results\n",
        "- Console output with refusal detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp1"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üß™ EXPERIMENT 1: Baseline Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "!python experiments/01_baseline.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úì Experiment 1 Complete\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXPadbpW2wM7"
      },
      "source": [
        "### Experiment 2: Activation Patching (Advanced)\n",
        "\n",
        "**Complete layer scanning** with logit-based metrics:\n",
        "- Scans ALL 32 layers √ó 3 components (MLPs, Residuals, Attention) = 96 experiments per prompt pair\n",
        "- Uses logit difference metrics (10-20x faster than text generation)\n",
        "- Includes ransomware bypass analysis\n",
        "\n",
        "**Expected outputs**:\n",
        "- `outputs/results/02_patching_results.json` - Complete results with logit metrics\n",
        "- `outputs/results/02_ransomware_bypass_analysis.json` - Bypass vulnerability analysis (if applicable)\n",
        "- `outputs/figures/01_causal_heatmap.html` - Interactive heatmap of causal effects\n",
        "- `outputs/figures/02_layer_importance.html` - Bar chart of layer importance\n",
        "- `outputs/figures/03_top_components.html` - Scatter plot of top 30 components\n",
        "- `outputs/figures/04_refusal_cascade.html` - Line plot showing cascade across layers\n",
        "- `outputs/figures/05_logit_statistics.html` - Detailed logit distribution comparison\n",
        "- `outputs/figures/06_ransomware_bypass.html` - Ransomware bypass visualization (if applicable)\n",
        "- `outputs/results/02_summary.csv` - CSV summary table\n",
        "\n",
        "**Runtime**: ~15-25 minutes on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp2"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üß™ EXPERIMENT 2: Activation Patching (Advanced)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚öôÔ∏è  Scanning all 32 layers with logit-based metrics...\")\n",
        "print(\"‚è±Ô∏è  Estimated time: 15-25 minutes on T4 GPU\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "!python experiments/02_patching.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úì Experiment 2 Complete\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nüìä Generated outputs:\")\n",
        "!ls -lh outputs/figures/*.html 2>/dev/null || echo \"No HTML files yet\"\n",
        "!ls -lh outputs/results/02_*.json outputs/results/02_*.csv 2>/dev/null || echo \"No result files yet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFNt0-y22wM7"
      },
      "source": [
        "### Experiment 3: Ablation Study\n",
        "\n",
        "Verifies that identified components are necessary for refusal behavior.\n",
        "\n",
        "**Expected outputs**:\n",
        "- `outputs/results/03_ablation_results.json` - Ablation results\n",
        "- Console output showing refusal reduction when components are ablated\n",
        "\n",
        "**Runtime**: ~5-10 minutes on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exp3"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üß™ EXPERIMENT 3: Ablation Study\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚öôÔ∏è  Testing necessity of identified components...\")\n",
        "print(\"‚è±Ô∏è  Estimated time: 5-10 minutes on T4 GPU\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "!python experiments/03_ablation.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úì Experiment 3 Complete\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1D7eBIf2wM7"
      },
      "source": [
        "## üìä Interactive Visualizations\n",
        "\n",
        "Display all 6 comprehensive visualizations generated from Experiment 2.\n",
        "\n",
        "**Visualizations included**:\n",
        "1. **Causal Heatmap**: Effects across all layers and components\n",
        "2. **Layer Importance**: Max/mean effects per layer\n",
        "3. **Top Components**: Scatter plot of top 30 by magnitude\n",
        "4. **Refusal Cascade**: Line plot showing effect progression\n",
        "5. **Logit Statistics**: Distribution comparison (harmful/harmless/patched)\n",
        "6. **Ransomware Bypass**: L2 distance analysis (if applicable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "!python experiments/02_patching.py\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, '/content/abstract/src')\n",
        "\n",
        "# Import visualization module\n",
        "from colab_visualization import display_in_colab\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä DISPLAYING INTERACTIVE VISUALIZATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Display all generated visualizations\n",
        "figures_dir = Path('/content/abstract/outputs/figures')\n",
        "\n",
        "if figures_dir.exists():\n",
        "    html_files = sorted(figures_dir.glob('*.html'))\n",
        "    \n",
        "    if html_files:\n",
        "        print(f\"\\n‚úì Found {len(html_files)} visualization(s)\\n\")\n",
        "        \n",
        "        for html_file in html_files:\n",
        "            print(f\"\\n{'=' * 60}\")\n",
        "            print(f\"üìà {html_file.stem.replace('_', ' ').title()}\")\n",
        "            print(\"=\" * 60)\n",
        "            display_in_colab(str(html_file))\n",
        "    else:\n",
        "        print(\"\\n‚ùå No HTML files found. Please run Experiment 2 first.\")\n",
        "        print(\"   Command: !python experiments/02_patching.py\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Figures directory not found. Please run Experiment 2 first.\")\n",
        "    print(\"   Command: !python experiments/02_patching.py\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úì Visualization Display Complete\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Download Results\n",
        "\n",
        "Download all results and visualizations to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üì¶ PREPARING DOWNLOAD PACKAGE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create zip archive\n",
        "zip_path = '/content/llama_refusal_results.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Add all result files\n",
        "    for root, dirs, file_list in os.walk('/content/abstract/outputs'):\n",
        "        for file in file_list:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, '/content/abstract')\n",
        "            zipf.write(file_path, arcname)\n",
        "            print(f\"  ‚úì Added: {arcname}\")\n",
        "\n",
        "# Get zip size\n",
        "zip_size = os.path.getsize(zip_path) / (1024 * 1024)  # MB\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"‚úì Archive created: {zip_size:.2f} MB\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nüì• Downloading...\")\n",
        "\n",
        "# Download\n",
        "files.download(zip_path)\n",
        "\n",
        "print(\"\\n‚úì Download complete!\")\n",
        "print(\"\\nüìÇ Package includes:\")\n",
        "print(\"  - outputs/results/*.json - All experiment results\")\n",
        "print(\"  - outputs/results/*.csv - Summary tables\")\n",
        "print(\"  - outputs/figures/*.html - Interactive visualizations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Additional Resources\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "This research identifies:\n",
        "- **Top 15-20 causal components** responsible for refusal behavior\n",
        "- **Layer importance ranking** across all 32 Llama-3.1 layers\n",
        "- **Ransomware bypass mechanism** (if vulnerability detected)\n",
        "- **Logit-based metrics** providing precise measurements\n",
        "\n",
        "### Metric Explanation\n",
        "\n",
        "**Logit Difference** = mean(refusal_token_logits) - mean(compliance_token_logits)\n",
        "- Positive values ‚Üí Model prefers refusal tokens\n",
        "- Negative values ‚Üí Model prefers compliance tokens\n",
        "- Used instead of text generation (10-20x faster, more precise)\n",
        "\n",
        "### Files Generated\n",
        "\n",
        "| File | Description | Format |\n",
        "|------|-------------|--------|\n",
        "| `01_baseline_results.json` | Baseline harmful/harmless responses | JSON |\n",
        "| `02_patching_results.json` | Complete patching results with logit metrics | JSON |\n",
        "| `02_ransomware_bypass_analysis.json` | Bypass vulnerability analysis | JSON |\n",
        "| `02_summary.csv` | Top components summary table | CSV |\n",
        "| `01_causal_heatmap.html` | Interactive heatmap visualization | Plotly HTML |\n",
        "| `02_layer_importance.html` | Layer importance bar chart | Plotly HTML |\n",
        "| `03_top_components.html` | Top 30 components scatter plot | Plotly HTML |\n",
        "| `04_refusal_cascade.html` | Cascade across layers line plot | Plotly HTML |\n",
        "| `05_logit_statistics.html` | Logit distribution comparison | Plotly HTML |\n",
        "| `06_ransomware_bypass.html` | Ransomware bypass analysis | Plotly HTML |\n",
        "| `03_ablation_results.json` | Ablation study results | JSON |\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "**Issue**: Model fails to load\n",
        "- **Solution**: Verify HF_TOKEN is set in Colab secrets with correct permissions\n",
        "\n",
        "**Issue**: CUDA out of memory\n",
        "- **Solution**: Restart runtime, ensure T4 GPU is selected (Runtime ‚Üí Change runtime type)\n",
        "\n",
        "**Issue**: Visualizations not displaying\n",
        "- **Solution**: Run Experiment 2 first (`!python experiments/02_patching.py`)\n",
        "\n",
        "### Citation\n",
        "\n",
        "If you use this research, please cite:\n",
        "```\n",
        "Llama-3.1 Refusal Mechanism Analysis\n",
        "Mechanistic Interpretability Research on Safety Refusal Behaviors\n",
        "https://github.com/weissv/abstract\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
